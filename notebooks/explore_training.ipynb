{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "# Add the parent directory to the sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "#import simtrain\n",
    "from simtrain.sim_models_new import User_simmulation_Model\n",
    "from simtrain import SETTINGS_POLIMI as SETTINGS\n",
    "from simtrain import explore_models, process_dat\n",
    "import simtrain.utils as utils\n",
    "from simtrain.Dataset import CustomDataset\n",
    "from simtrain.train import train, train_with_negatives\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import ast\n",
    "\n",
    "import paths\n",
    "from os.path import join\n",
    "import pytorch_warmup as warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_items = 7\n",
    "#num_items_per_recom = 2\n",
    "num_interaction_types = 2\n",
    "recom_dim = 1\n",
    "#num_users = 11\n",
    "#min_inter = 2\n",
    "#max_inter = 4\n",
    "state_size = SETTINGS.STATE_SIZE\n",
    "subset = 50 # make data smaller\n",
    "experiment_name = \"new_negative2\"\n",
    "num_negatives = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NI': 14, 'NU': 328, 'T': '[9.708333333333334, 12.4375, 12.604166666666666, 13.395833333333334, 15.458333333333334, 15.979166666666666, 17.333333333333332, 18.6875, 20.58333333333333, 21.354166666666668, 21.375, 21.39583333333333, 21.416666666666668, 21.4375, 21.45833333333333, 21.479166666666668, 22.52083333333333, 24.39583333333333, 24.416666666666668, 24.4375, 24.45833333333333, 24.479166666666668, 24.5, 24.52083333333333, 25.479166666666668, 25.5, 25.52083333333333, 25.541666666666668, 25.58333333333333, 25.64583333333333, 29.33333333333333, 30.14583333333333, 30.58333333333333, 30.604166666666668, 30.625, 30.979166666666668, 32.0, 34.354166666666664, 36.66666666666666, 36.6875, 37.5625, 37.583333333333336, 38.583333333333336, 43.10416666666666, 43.333333333333336]', 'NS': 100, 'INF_TIME': 1000}\n",
      "len:  328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_means</th>\n",
       "      <th>user_vars_log</th>\n",
       "      <th>item_ids</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>interaction_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188</td>\n",
       "      <td>[0.04783848150114567, 0.7924748444992165, -0.9...</td>\n",
       "      <td>[-4.548759966682498, -3.073818977358924, -0.91...</td>\n",
       "      <td>[[119, 74, 263, 144, 261, 53, 217, 194, 178, 2...</td>\n",
       "      <td>[5.416666666666667, 12.25, 13.645833333333334,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>491</td>\n",
       "      <td>[0.9822065088026923, -0.30920177438877716, -0....</td>\n",
       "      <td>[-1.7784866608889747, -0.999038985048541, -0.1...</td>\n",
       "      <td>[[144, 279, 79, 84, 74, 247, 162, 165, 161, 13...</td>\n",
       "      <td>[54.35416666666666, 57.270833333333336, 57.354...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>561</td>\n",
       "      <td>[-0.6958705564906345, -0.9186835528229786, -0....</td>\n",
       "      <td>[-1.7702656832363624, -4.848853170981278, -0.2...</td>\n",
       "      <td>[[106, 125, 158, 27, 269, 264, 110, 50, 19, 16...</td>\n",
       "      <td>[20.58333333333333, 26.64583333333333, 28.5625...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670</td>\n",
       "      <td>[-0.20785380515949425, -0.576465807579132, -0....</td>\n",
       "      <td>[-4.164488517462706, -4.8280370081718305, -2.0...</td>\n",
       "      <td>[[165, 157, 187, 155, 95, 202, 99, 237, 288, 5...</td>\n",
       "      <td>[20.33333333333333, 26.39583333333333, 35.3125...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>749</td>\n",
       "      <td>[0.991729030223963, -0.13849834840449438, 0.61...</td>\n",
       "      <td>[-2.553989406915311, -4.1900085632639765, -1.4...</td>\n",
       "      <td>[[161, 199, 279, 12, 37, 84, 74, 132, 161, 284...</td>\n",
       "      <td>[5.083333333333333, 6.395833333333333, 11.8125...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                         user_means  \\\n",
       "0      188  [0.04783848150114567, 0.7924748444992165, -0.9...   \n",
       "1      491  [0.9822065088026923, -0.30920177438877716, -0....   \n",
       "2      561  [-0.6958705564906345, -0.9186835528229786, -0....   \n",
       "3      670  [-0.20785380515949425, -0.576465807579132, -0....   \n",
       "4      749  [0.991729030223963, -0.13849834840449438, 0.61...   \n",
       "\n",
       "                                       user_vars_log  \\\n",
       "0  [-4.548759966682498, -3.073818977358924, -0.91...   \n",
       "1  [-1.7784866608889747, -0.999038985048541, -0.1...   \n",
       "2  [-1.7702656832363624, -4.848853170981278, -0.2...   \n",
       "3  [-4.164488517462706, -4.8280370081718305, -2.0...   \n",
       "4  [-2.553989406915311, -4.1900085632639765, -1.4...   \n",
       "\n",
       "                                            item_ids  \\\n",
       "0  [[119, 74, 263, 144, 261, 53, 217, 194, 178, 2...   \n",
       "1  [[144, 279, 79, 84, 74, 247, 162, 165, 161, 13...   \n",
       "2  [[106, 125, 158, 27, 269, 264, 110, 50, 19, 16...   \n",
       "3  [[165, 157, 187, 155, 95, 202, 99, 237, 288, 5...   \n",
       "4  [[161, 199, 279, 12, 37, 84, 74, 132, 161, 284...   \n",
       "\n",
       "                                          timestamps  \\\n",
       "0  [5.416666666666667, 12.25, 13.645833333333334,...   \n",
       "1  [54.35416666666666, 57.270833333333336, 57.354...   \n",
       "2  [20.58333333333333, 26.64583333333333, 28.5625...   \n",
       "3  [20.33333333333333, 26.39583333333333, 35.3125...   \n",
       "4  [5.083333333333333, 6.395833333333333, 11.8125...   \n",
       "\n",
       "                                   interaction_types  \n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, ...  \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataset from processed data\n",
    "'''\n",
    "train_dat, stg = process_dat.load_dat(paths.cw_stages['output_new']['train'], new_data=True)\n",
    "\n",
    "print(stg)\n",
    "\n",
    "def convert_string_to_double_list(s):\n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "# Apply the custom function\n",
    "train_dat['item_ids'] = train_dat['item_ids'].apply(convert_string_to_double_list)\n",
    "train_dat['user_means'] = train_dat['user_means'].apply(convert_string_to_double_list)\n",
    "train_dat['user_vars_log'] = train_dat['user_vars_log'].apply(convert_string_to_double_list)\n",
    "train_dat['timestamps'] = train_dat['timestamps'].apply(convert_string_to_double_list)\n",
    "train_dat['interaction_types'] = train_dat['interaction_types'].apply(convert_string_to_double_list)\n",
    "\n",
    "print(\"len: \", len(train_dat))\n",
    "list_of_dicts = train_dat.to_dict(orient='records')\n",
    "list_of_dicts = list_of_dicts[:subset]\n",
    "train_dat.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = torch.load(join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"data.h5\"))\n",
    "list_of_dicts = checkpoint['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef adjust_hidden_dim(data_dict, state_size):\\n    # just to jumstart experiments should be deleted at the end\\n    for row in list_of_dicts:\\n        if row[\"user_means\"] > state_size:\\n            row[\"user_means\"] = row[\"user_means\"][:state_size]\\n            row[\"user_vars_log\"] = row[\"user_vars_log\"][:state_size]\\n        elif row[\"user_means\"] > state_size:\\n\\n\\nadjust_hidden_dim(list_of_dicts, state_size)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def adjust_hidden_dim(data_dict, state_size):\n",
    "    # just to jumstart experiments should be deleted at the end\n",
    "    for row in list_of_dicts:\n",
    "        if row[\"user_means\"] > state_size:\n",
    "            row[\"user_means\"] = row[\"user_means\"][:state_size]\n",
    "            row[\"user_vars_log\"] = row[\"user_vars_log\"][:state_size]\n",
    "        elif row[\"user_means\"] > state_size:\n",
    "\n",
    "\n",
    "adjust_hidden_dim(list_of_dicts, state_size)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = CustomDataset(list_of_dicts[:30]) # [:30]\n",
    "# Example usage with DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)# can only do batchsize 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "69.33333333333333\n"
     ]
    }
   ],
   "source": [
    "def test_timestamps(dataloader):\n",
    "    smallest = float(\"inf\")\n",
    "    biggest = -1\n",
    "    for batch in dataloader:\n",
    "        timestamps, items, labels, means, var, idx = batch\n",
    "        last = timestamps[0]\n",
    "        smallest = min(smallest, last)\n",
    "        biggest = max(biggest, timestamps[-1])\n",
    "        for i in range(1,len(timestamps)):\n",
    "            if timestamps[i] <= last:\n",
    "                print(\"error, current: \", timestamps[i], \"\\tlast\", last)\n",
    "    smallest, biggest= int(smallest), float(biggest)\n",
    "    print(smallest), print(biggest)\n",
    "    return biggest\n",
    "\n",
    "max_time = test_timestamps(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps: [tensor([1.3750], dtype=torch.float64), tensor([15.5625], dtype=torch.float64), tensor([15.6042], dtype=torch.float64), tensor([19.2292], dtype=torch.float64), tensor([19.2917], dtype=torch.float64), tensor([38.3333], dtype=torch.float64)]\n",
      "item_recom: [[tensor([217]), tensor([2]), tensor([53]), tensor([66]), tensor([297]), tensor([50]), tensor([199]), tensor([192]), tensor([77]), tensor([2]), tensor([57]), tensor([31]), tensor([109]), tensor([153]), tensor([88]), tensor([103]), tensor([205]), tensor([217]), tensor([60]), tensor([20]), tensor([238]), tensor([159]), tensor([203]), tensor([178]), tensor([254]), tensor([168]), tensor([298]), tensor([205]), tensor([2]), tensor([138]), tensor([20]), tensor([77]), tensor([50]), tensor([297]), tensor([66]), tensor([205]), tensor([57]), tensor([53]), tensor([66]), tensor([297]), tensor([50]), tensor([192]), tensor([153]), tensor([199]), tensor([217]), tensor([238]), tensor([88]), tensor([199]), tensor([50]), tensor([192]), tensor([66]), tensor([53]), tensor([297]), tensor([2]), tensor([205]), tensor([217]), tensor([60]), tensor([77])], [tensor([74]), tensor([199]), tensor([238]), tensor([20]), tensor([2]), tensor([77]), tensor([62]), tensor([138]), tensor([159]), tensor([178]), tensor([66]), tensor([53]), tensor([57]), tensor([203]), tensor([74]), tensor([108]), tensor([50]), tensor([132]), tensor([297]), tensor([168]), tensor([168]), tensor([217]), tensor([134]), tensor([276]), tensor([66]), tensor([134]), tensor([238]), tensor([60]), tensor([108]), tensor([138]), tensor([159]), tensor([203]), tensor([178]), tensor([57]), tensor([168]), tensor([159]), tensor([203]), tensor([178]), tensor([57]), tensor([132]), tensor([138]), tensor([205]), tensor([238]), tensor([74]), tensor([66]), tensor([284]), tensor([205]), tensor([217]), tensor([50]), tensor([261]), tensor([2]), tensor([153]), tensor([53]), tensor([66]), tensor([276]), tensor([205]), tensor([261]), tensor([50]), tensor([284]), tensor([297]), tensor([66]), tensor([53]), tensor([2]), tensor([153]), tensor([297]), tensor([217]), tensor([66]), tensor([108]), tensor([74]), tensor([108]), tensor([238]), tensor([276]), tensor([108]), tensor([132]), tensor([74]), tensor([134]), tensor([66]), tensor([276]), tensor([66]), tensor([132]), tensor([134]), tensor([132]), tensor([134]), tensor([238]), tensor([238]), tensor([276])], [tensor([108]), tensor([134]), tensor([238]), tensor([276]), tensor([203]), tensor([57]), tensor([178]), tensor([159]), tensor([132]), tensor([66]), tensor([74]), tensor([57]), tensor([60]), tensor([77]), tensor([199]), tensor([50]), tensor([205]), tensor([53]), tensor([205]), tensor([217]), tensor([66]), tensor([168]), tensor([195]), tensor([138]), tensor([66]), tensor([297]), tensor([238]), tensor([138]), tensor([168]), tensor([159]), tensor([20]), tensor([178]), tensor([57]), tensor([195]), tensor([192]), tensor([50]), tensor([284]), tensor([203]), tensor([66]), tensor([297]), tensor([60]), tensor([60]), tensor([50]), tensor([20]), tensor([77]), tensor([2]), tensor([205]), tensor([53]), tensor([199])], [tensor([108]), tensor([205]), tensor([134]), tensor([238]), tensor([276]), tensor([66]), tensor([74]), tensor([276]), tensor([108]), tensor([134]), tensor([238]), tensor([205]), tensor([66]), tensor([74]), tensor([132]), tensor([66]), tensor([132]), tensor([108]), tensor([74]), tensor([153]), tensor([2]), tensor([50]), tensor([134]), tensor([66]), tensor([53]), tensor([205]), tensor([271]), tensor([297]), tensor([132]), tensor([205]), tensor([276]), tensor([238]), tensor([134]), tensor([217])], [tensor([66]), tensor([50]), tensor([192]), tensor([134]), tensor([2]), tensor([66]), tensor([217]), tensor([153]), tensor([66]), tensor([276]), tensor([297]), tensor([205]), tensor([199]), tensor([238]), tensor([108]), tensor([217]), tensor([74]), tensor([53]), tensor([66]), tensor([297]), tensor([77]), tensor([2]), tensor([50]), tensor([132]), tensor([50]), tensor([134]), tensor([217]), tensor([57]), tensor([53]), tensor([205]), tensor([261]), tensor([217]), tensor([53]), tensor([66]), tensor([297]), tensor([290]), tensor([50]), tensor([2]), tensor([195]), tensor([271]), tensor([134]), tensor([2]), tensor([205]), tensor([53]), tensor([153]), tensor([297]), tensor([66]), tensor([50]), tensor([297]), tensor([284]), tensor([2]), tensor([205]), tensor([205]), tensor([217]), tensor([205]), tensor([53])], [tensor([60]), tensor([153]), tensor([60]), tensor([205]), tensor([20]), tensor([297]), tensor([66]), tensor([53]), tensor([2]), tensor([2]), tensor([238]), tensor([272]), tensor([66]), tensor([276]), tensor([272]), tensor([134]), tensor([238]), tensor([2]), tensor([238]), tensor([134]), tensor([20]), tensor([217]), tensor([261]), tensor([50]), tensor([297]), tensor([66]), tensor([205]), tensor([217]), tensor([57]), tensor([276]), tensor([284]), tensor([195]), tensor([2]), tensor([276]), tensor([178]), tensor([203]), tensor([159]), tensor([168]), tensor([138]), tensor([199]), tensor([77]), tensor([238]), tensor([41]), tensor([57]), tensor([66]), tensor([276]), tensor([238]), tensor([66]), tensor([238]), tensor([272]), tensor([134]), tensor([276]), tensor([2]), tensor([276]), tensor([134]), tensor([238]), tensor([272]), tensor([2]), tensor([66]), tensor([134]), tensor([272]), tensor([238]), tensor([276]), tensor([2]), tensor([66]), tensor([66]), tensor([2]), tensor([272]), tensor([276]), tensor([66]), tensor([272]), tensor([276]), tensor([66]), tensor([276]), tensor([238]), tensor([66]), tensor([272]), tensor([238]), tensor([134]), tensor([134]), tensor([2]), tensor([2]), tensor([134]), tensor([238]), tensor([272]), tensor([134]), tensor([2]), tensor([66]), tensor([134]), tensor([238]), tensor([272]), tensor([50])]]\n",
      "Labels: [[tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])], [tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])]]\n",
      "means: [tensor([-0.5788], dtype=torch.float64), tensor([-0.0287], dtype=torch.float64), tensor([-0.1401], dtype=torch.float64), tensor([-0.0231], dtype=torch.float64)]\n",
      "log_var: [tensor([-4.3815], dtype=torch.float64), tensor([-1.4571], dtype=torch.float64), tensor([-0.5910], dtype=torch.float64), tensor([-2.3023], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    timestamps, items, labels, means, var, idx = batch\n",
    "    print('Timestamps:', timestamps#, \"\\n dtype: \", timestamps.dtype\n",
    "          )\n",
    "    print('item_recom:', items#, \"\\n dtype: \", items.dtype\n",
    "          )\n",
    "    print('Labels:', labels#, \"\\n dtype: \", labels.dtype\n",
    "          )\n",
    "    print('means:', means#, \"\\n dtype: \", means.dtype\n",
    "          )\n",
    "    print('log_var:', var#, \"\\n dtype: \", var.dtype\n",
    "          )\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter dicts\n",
    "width= 10\n",
    "user_state_dict = {\"model_hyp\": {\"layer_width\": [width, width, width]}}\n",
    "intensity_state_dict = {\"model_hyp\": {\"user_model_hyp\": {\"layer_width\": [width, width],\n",
    "                                                         \"noise\": 0},\n",
    "                                          \"global_model_hyp\": {\"layer_width\": [width, 3]}}\n",
    "                            }\n",
    "interaction_state_dict = {\"model_hyp\": {\"layer_width\": [width, width ,width]}\n",
    "                            }\n",
    "jump_state_dict = {\"model_hyp\": {\"layer_width\": [width, width]}\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "hyperparameter_dict = {\"state_size\": state_size, \"state_model\": user_state_dict, \"num_interaction_outcomes\": num_interaction_types,\n",
    "                           \"intensity_model\": intensity_state_dict,# \"num_recom\" : num_items_per_recom,\n",
    "                            \"recom_dim\":recom_dim, \"interaction_model\": interaction_state_dict,\n",
    "                            \"jump_model\": jump_state_dict, \"user_params_size\": state_size}\n",
    "model = User_simmulation_Model(hyperparameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "path = join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"user_model.h5\")\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "warmup_period = len(dataset)\n",
    "num_steps = num_epochs*len(dataset) -warmup_period\n",
    "num_iter_til_first_restart = num_steps//2\n",
    "user_lr = 0.1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.02,\n",
    "                        weight_decay=1e-7)\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=num_iter_til_first_restart, T_mult=1, eta_min=5e-5)\n",
    "\n",
    "warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  [tensor([-0.1650], dtype=torch.float64), tensor([-0.8327], dtype=torch.float64), tensor([-0.0119], dtype=torch.float64), tensor([0.5459], dtype=torch.float64)]\n",
      "logvar:  [tensor([-1.1950], dtype=torch.float64), tensor([-4.4349], dtype=torch.float64), tensor([-0.4462], dtype=torch.float64), tensor([-3.3404], dtype=torch.float64)]\n",
      "means:  [tensor([-0.2079], dtype=torch.float64), tensor([-0.5765], dtype=torch.float64), tensor([-0.4390], dtype=torch.float64), tensor([-0.7407], dtype=torch.float64)]\n",
      "logvar:  [tensor([-4.1645], dtype=torch.float64), tensor([-4.8280], dtype=torch.float64), tensor([-2.0535], dtype=torch.float64), tensor([-2.3040], dtype=torch.float64)]\n",
      "means:  [tensor([-0.7124], dtype=torch.float64), tensor([0.0909], dtype=torch.float64), tensor([-0.2352], dtype=torch.float64), tensor([-0.3719], dtype=torch.float64)]\n",
      "logvar:  [tensor([-4.4651], dtype=torch.float64), tensor([-2.6311], dtype=torch.float64), tensor([-2.4612], dtype=torch.float64), tensor([-1.5865], dtype=torch.float64)]\n",
      "means:  [tensor([-0.9124], dtype=torch.float64), tensor([-0.4502], dtype=torch.float64), tensor([-0.5846], dtype=torch.float64), tensor([-0.7026], dtype=torch.float64)]\n",
      "logvar:  [tensor([-2.8323], dtype=torch.float64), tensor([-2.3594], dtype=torch.float64), tensor([-1.0719], dtype=torch.float64), tensor([-4.8986], dtype=torch.float64)]\n",
      "means:  [tensor([-0.3184], dtype=torch.float64), tensor([0.6238], dtype=torch.float64), tensor([-0.6648], dtype=torch.float64), tensor([-0.1565], dtype=torch.float64)]\n",
      "logvar:  [tensor([-4.9636], dtype=torch.float64), tensor([-4.0032], dtype=torch.float64), tensor([-4.9771], dtype=torch.float64), tensor([-0.3125], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "utils.print_user_params(dataloader, print_var = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain(model, dataloader=dataloader, num_epochs=num_epochs, device=device, loss_func=utils.loss_func, \\n                loss_func_kl=utils.kl_loss, kl_weight=1., user_lr=user_lr,\\n                optimizer=optimizer, lr_scheduler=lr_scheduler, num_classes=num_interaction_types, \\n                logger=utils.logging_func,warmup_period=warmup_period, intensity_loss_func=utils.square_intensity_loss,\\n                state_size=state_size,max_time=max_time, log_step_size=1, warmup_scheduler = warmup_scheduler,\\n                )\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no negative samples\n",
    "'''\n",
    "train(model, dataloader=dataloader, num_epochs=num_epochs, device=device, loss_func=utils.loss_func, \n",
    "                loss_func_kl=utils.kl_loss, kl_weight=1., user_lr=user_lr,\n",
    "                optimizer=optimizer, lr_scheduler=lr_scheduler, num_classes=num_interaction_types, \n",
    "                logger=utils.logging_func,warmup_period=warmup_period, intensity_loss_func=utils.square_intensity_loss,\n",
    "                state_size=state_size,max_time=max_time, log_step_size=1, warmup_scheduler = warmup_scheduler,\n",
    "                )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "underflow in dt 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27129/1365316001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mwarmup_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintensity_loss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_step_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarmup_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mnum_negatives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_negatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_examples_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 )\n",
      "\u001b[0;32m~/github/Recommender_Sim/simtrain/train.py\u001b[0m in \u001b[0;36mtrain_with_negatives\u001b[0;34m(model, device, dataloader, num_epochs, state_size, loss_func, loss_func_kl, optimizer, num_classes, intensity_loss_func, logger, max_time, lr_scheduler, warmup_scheduler, kl_weight, user_lr, log_step_size, warmup_period, num_negatives, positive_examples_weight)\u001b[0m\n\u001b[1;32m    203\u001b[0m                          \u001b[0mloss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                          \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintensity_loss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintensity_loss_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                          positive_examples_weight=positive_examples_weight)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mcurr_loss_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkl_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func_kl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.view(1,-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Recommender_Sim/simtrain/train.py\u001b[0m in \u001b[0;36mtrain_1_path_positive_and_negative\u001b[0;34m(model, user_state, timestamps, items, labels, loss_func, num_classes, intensity_loss_func, max_time, device, epsilon, teacher_forcing, positive_examples_weight)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimestamps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minteraction_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurr_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# update time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mintensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;31m#epsilon for stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Recommender_Sim/simtrain/sim_models_new.py\u001b[0m in \u001b[0;36meval_intensity\u001b[0;34m(self, h, return_all)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIntensity\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \"\"\"\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0moverall_intensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_intensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_intensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintensity_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moverall_intensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_intensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_intensity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Recommender_Sim/simtrain/sim_models_new.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, time, state_model)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \"\"\"\n\u001b[1;32m    458\u001b[0m         \u001b[0mintensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0muser_intensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0mintensity\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0muser_intensity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;31m# time might need to be incoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Recommender_Sim/simtrain/sim_models_new.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, time, state, state_model, h_0, interval_time)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_intervals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterval_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minterval_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Recommender_Sim/simtrain/sim_models_new.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, start_state, h, h_0)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# can specify max error if desired\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mh_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mode_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# h_t contains the states at t=0 and t=h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mend_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mnext_t\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_num_steps exceeded ({}>={})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adaptive_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0mn_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_interp_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp_coeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m#                      Assertions                      #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'underflow in dt {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'non-finite values in state `y`: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: underflow in dt 0.0"
     ]
    }
   ],
   "source": [
    "train_with_negatives(model, dataloader=dataloader, num_epochs=num_epochs, device=device, \n",
    "                loss_func=utils.loss_func, loss_func_kl=utils.kl_loss, kl_weight=1., \n",
    "                user_lr=user_lr, optimizer=optimizer, lr_scheduler=lr_scheduler, \n",
    "                num_classes=num_interaction_types, logger=utils.logging_func,\n",
    "                warmup_period=warmup_period, intensity_loss_func=utils.log_loss,\n",
    "                state_size=state_size,max_time=max_time, log_step_size=1, warmup_scheduler = warmup_scheduler,\n",
    "                num_negatives=num_negatives, positive_examples_weight=1,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  [tensor([0.0020], dtype=torch.float64), tensor([0.0003], dtype=torch.float64), tensor([-0.0003], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.5196], dtype=torch.float64), tensor([-0.5196], dtype=torch.float64), tensor([-0.5196], dtype=torch.float64)]\n",
      "means:  [tensor([-0.0076], dtype=torch.float64), tensor([-0.0022], dtype=torch.float64), tensor([0.0018], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.5774], dtype=torch.float64), tensor([-0.5774], dtype=torch.float64), tensor([-0.5774], dtype=torch.float64)]\n",
      "means:  [tensor([0.0010], dtype=torch.float64), tensor([0.0013], dtype=torch.float64), tensor([-0.0005], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.5196], dtype=torch.float64), tensor([-0.5196], dtype=torch.float64), tensor([-0.5196], dtype=torch.float64)]\n",
      "means:  [tensor([-0.0024], dtype=torch.float64), tensor([0.1395], dtype=torch.float64), tensor([-0.1428], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.4619], dtype=torch.float64), tensor([-0.4619], dtype=torch.float64), tensor([-0.4619], dtype=torch.float64)]\n",
      "means:  [tensor([0.1664], dtype=torch.float64), tensor([0.0264], dtype=torch.float64), tensor([-0.0940], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.4619], dtype=torch.float64), tensor([-0.4619], dtype=torch.float64), tensor([-0.4619], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "utils.print_user_params(dataloader, print_var = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "path = join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"user_model.h5\")\n",
    "\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data(changes during training)\n",
    "path = join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"data.h5\")\n",
    "torch.save({\n",
    "    'data': dataloader.dataset.data,\n",
    "}, path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total visits for user 6\n",
      "overall_intensity:  tensor([[0.5000]]) \tuser_intensity:  tensor([[0.5000]]) \tglobal_intensity:  tensor([0.]) \t before a recommendation.\n",
      "overall_intensity:  tensor([[0.5000]]) \tuser_intensity:  tensor([[0.5000]]) \tglobal_intensity:  tensor([0.]) \t before a recommendation.\n",
      "overall_intensity:  tensor([[0.5000]]) \tuser_intensity:  tensor([[0.5000]]) \tglobal_intensity:  tensor([0.]) \t before a recommendation.\n",
      "overall_intensity:  tensor([[0.5000]]) \tuser_intensity:  tensor([[0.5000]]) \tglobal_intensity:  tensor([0.]) \t before a recommendation.\n",
      "overall_intensity:  tensor([[0.5000]]) \tuser_intensity:  tensor([[0.5000]]) \tglobal_intensity:  tensor([0.]) \t before a recommendation.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_models.plot_rnd_user_visits_new(state_size, max_time=max_time, dataset=dataloader.dataset,\n",
    "                    User_model = model, use_true_recommendations =True, num_classes = num_interaction_types,\n",
    "                        teacher_forcing =True, user_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
