{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# Add the parent directory to the sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now you can import file1\n",
    "#import simtrain\n",
    "from simtrain.sim_models_new import User_simmulation_Model\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = 7\n",
    "num_items_per_recom = 2\n",
    "num_interaction_types = 2\n",
    "recom_dim = 1\n",
    "num_users = 11\n",
    "min_inter = 2\n",
    "max_inter = 4\n",
    "state_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps: tensor([[0.0822, 0.4975, 0.5484]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[4.],\n",
      "          [4.]],\n",
      "\n",
      "         [[1.],\n",
      "          [3.]],\n",
      "\n",
      "         [[2.],\n",
      "          [3.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[-0.3341, -0.9852]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[0.9213, 0.8606]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "Timestamps: tensor([[0.0483, 0.8681]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[3.],\n",
      "          [1.]],\n",
      "\n",
      "         [[4.],\n",
      "          [2.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[-0.4827, -0.7810]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[-0.7085,  0.9509]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "Timestamps: tensor([[0.4861, 0.4927, 0.7249]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[1.],\n",
      "          [4.]],\n",
      "\n",
      "         [[3.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [3.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[-0.3777,  0.8752]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[-0.5233, -1.1403]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "Timestamps: tensor([[0.0833, 0.3044]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[3.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [4.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[-0.3347,  0.5144]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[ 1.3193, -0.9432]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "Timestamps: tensor([[0.1434, 0.3115]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[4.],\n",
      "          [2.]],\n",
      "\n",
      "         [[1.],\n",
      "          [3.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[-1.1417,  1.6132]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[-0.3386,  0.7236]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "Timestamps: tensor([[0.1974, 0.5558, 0.8390, 0.9350]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[4.],\n",
      "          [2.]],\n",
      "\n",
      "         [[2.],\n",
      "          [4.]],\n",
      "\n",
      "         [[4.],\n",
      "          [1.]],\n",
      "\n",
      "         [[4.],\n",
      "          [2.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[-0.5567,  0.6752]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[-1.0781, -1.2146]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "Timestamps: tensor([[0.2198, 0.2371, 0.9054]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[4.],\n",
      "          [2.]],\n",
      "\n",
      "         [[2.],\n",
      "          [4.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[0.9434, 0.3297]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[0.2264, 0.6793]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "Timestamps: tensor([[0.5533, 0.7926]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[3.],\n",
      "          [1.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[-0.8823,  0.6713]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[0.1240, 0.8507]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "Timestamps: tensor([[0.0074, 0.9815]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[2.],\n",
      "          [3.]],\n",
      "\n",
      "         [[1.],\n",
      "          [4.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[-1.6682,  1.0347]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[-0.5324,  0.0204]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "Timestamps: tensor([[0.0636, 0.3956, 0.7094, 0.7780]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[1.],\n",
      "          [3.]],\n",
      "\n",
      "         [[1.],\n",
      "          [4.]],\n",
      "\n",
      "         [[3.],\n",
      "          [2.]],\n",
      "\n",
      "         [[1.],\n",
      "          [4.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[ 0.1913, -0.9979]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[-0.3750,  0.5932]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "Timestamps: tensor([[0.2364, 0.2727, 0.6763]]) \n",
      " dtype:  torch.float32\n",
      "item_recom: tensor([[[[3.],\n",
      "          [3.]],\n",
      "\n",
      "         [[3.],\n",
      "          [3.]],\n",
      "\n",
      "         [[4.],\n",
      "          [4.]]]]) \n",
      " dtype:  torch.float32\n",
      "Labels: tensor([[[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]]]) \n",
      " dtype:  torch.int64\n",
      "means: tensor([[-0.9807,  0.4182]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n",
      "log_var: tensor([[-1.2250, -0.9406]], grad_fn=<StackBackward0>) \n",
      " dtype:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (list of dicts): Each dict contains 'timestamps', 'items', and 'labels' for a user.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_data = self.data[idx]\n",
    "        timestamps = user_data['timestamps']\n",
    "        items =  user_data['item_recom']\n",
    "        labels = user_data['labels']\n",
    "        return timestamps, items, labels, user_data[\"means\"], user_data[\"log_var\"], idx\n",
    "    def Update_user_params(self, means_list, logvar_list, idx_list):\n",
    "        means_list.requires_grad = True\n",
    "        logvar_list.requires_grad = True\n",
    "        \n",
    "        for means, logvar, idx in zip(means_list, logvar_list, idx_list):\n",
    "            self.data[idx][\"means\"] = means\n",
    "            self.data[idx][\"log_var\"] = logvar\n",
    "\n",
    "# Example data for multiple users\n",
    "\n",
    "data = []\n",
    "for user in range(num_users):\n",
    "    num_interactions_now = random.randint(a=min_inter, b=max_inter)\n",
    "    new = {\n",
    "        'item_recom': torch.randint(low=1, high=num_items, size=(num_interactions_now, \n",
    "        num_items_per_recom, recom_dim)).to(torch.float32),\n",
    "        'timestamps': torch.sort(torch.FloatTensor(num_interactions_now).uniform_(0, 1.))[0].to(torch.float32),\n",
    "        'labels': torch.randint(low=0, high=num_interaction_types-1, \n",
    "        size=(num_interactions_now, num_items_per_recom)),\n",
    "        \"means\": torch.randn((state_size), requires_grad=True).to(torch.float32),\n",
    "        \"log_var\": torch.randn((state_size), requires_grad=True).to(torch.float32),\n",
    "    }\n",
    "    data.append(new)\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "dataset = CustomDataset(data)\n",
    "\n",
    "# Example usage with DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)# can only do batchsize 1\n",
    "\n",
    "for batch in dataloader:\n",
    "    timestamps, items, labels, means, var, idx = batch\n",
    "    print('Timestamps:', timestamps, \"\\n dtype: \", timestamps.dtype)\n",
    "    print('item_recom:', items, \"\\n dtype: \", items.dtype)\n",
    "    print('Labels:', labels, \"\\n dtype: \", labels.dtype)\n",
    "    print('means:', means, \"\\n dtype: \", means.dtype)\n",
    "    print('log_var:', var, \"\\n dtype: \", var.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1_path(model, user_state, timestamps, items, labels, loss_func, num_classes, teacher_forcing=True):\n",
    "    ''' expects batchsize of 1\n",
    "    '''\n",
    "    model.init_state(user_state)\n",
    "    loss = 0.\n",
    "    curr_time = 0.\n",
    "    \n",
    "    for interaction_id in range(len(timestamps[0])):\n",
    "        \n",
    "        h = timestamps[0][interaction_id] - curr_time\n",
    "        curr_time = h\n",
    "        model.evolve_state(h)\n",
    "        # no intensity for now\n",
    "        y_pred = model.view_recommendations(items[:,interaction_id])\n",
    "        y_true = labels[:,interaction_id]\n",
    "        y_true_onehot = nn.functional.one_hot(y_true, num_classes=num_classes).float()\n",
    "        if teacher_forcing:\n",
    "            model.jump(y_true_onehot)\n",
    "        else:\n",
    "            model.jump(y_pred)\n",
    "        #loss += loss_func(y_true, y_pred)# for mse\n",
    "        y_true = y_true.squeeze(0)\n",
    "        y_pred = y_pred.squeeze(0)\n",
    "        #print(y_true, y_pred)\n",
    "        y_pred = nn.functional.log_softmax(y_pred,dim=-1)\n",
    "        loss += loss_func(y_pred, y_true) # NLLL\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter dicts\n",
    "width= 10\n",
    "user_state_dict = {\"model_hyp\": {\"layer_width\": [width, width, width]}}\n",
    "intensity_state_dict = {\"model_hyp\": {\"user_model_hyp\": {\"layer_width\": [width, width, 3]},\n",
    "                                          \"global_model_hyp\": {\"layer_width\": [width, 3]}}\n",
    "                            }\n",
    "interaction_state_dict = {\"model_hyp\": {\"layer_width\": [width, width ,width]}\n",
    "                            }\n",
    "jump_state_dict = {\"model_hyp\": {\"layer_width\": [width, width]}\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "hyperparameter_dict = {\"state_size\": state_size, \"state_model\": user_state_dict, \"num_interaction_outcomes\": num_interaction_types,\n",
    "                           \"intensity_model\": intensity_state_dict, \"num_recom\" : num_items_per_recom,\n",
    "                            \"recom_dim\":recom_dim, \"interaction_model\": interaction_state_dict,\n",
    "                            \"jump_model\": jump_state_dict}\n",
    "model = User_simmulation_Model(hyperparameter_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_func = nn.functional.mse_loss\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "def kl_divergence(mu1, sigma1, mu2, sigma2):\n",
    "    \"\"\"\n",
    "    Compute the KL divergence between two normal distributions N(mu1, sigma1^2) and N(mu2, sigma2^2).\n",
    "\n",
    "    Args:\n",
    "        mu1 (Tensor): Mean of the first distribution.\n",
    "        sigma1 (Tensor): Standard deviation of the first distribution.\n",
    "        mu2 (Tensor): Mean of the second distribution.\n",
    "        sigma2 (Tensor): Standard deviation of the second distribution.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: KL divergence.\n",
    "    \"\"\"\n",
    "    kl_div = torch.log(sigma2 / sigma1) + ((sigma1 ** 2 + (mu1 - mu2) ** 2) / (2 * sigma2 ** 2)) - 0.5\n",
    "    return kl_div\n",
    "\n",
    "def kl_divergence_to_standard_normal(mu, sigma):\n",
    "    \"\"\"\n",
    "    Compute the KL divergence from a normal distribution N(mu, sigma^2) to the standard normal distribution N(0, 1).\n",
    "\n",
    "    Args:\n",
    "        mu (Tensor): Mean of the normal distribution.\n",
    "        sigma (Tensor): Standard deviation of the normal distribution.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: KL divergence.\n",
    "    \"\"\"\n",
    "    sigma2 = sigma ** 2\n",
    "    kl_div = 0.5 * (sigma2 + mu ** 2 - torch.log(sigma2) - 1)\n",
    "    return kl_div\n",
    "\n",
    "def kl_loss (mu, sigma):\n",
    "    return kl_divergence(mu, sigma, 0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_user_params(datadataloader, print_var = False):\n",
    "    for batch in dataloader:\n",
    "        timestamps, item_recom, labels, means, logvar, idx = batch\n",
    "        print(\"means: \", means)\n",
    "        if (print_var):\n",
    "            print(\"logvar: \", logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, dataloader,num_epochs, state_size, loss_func, loss_func_kl, optimizer, num_classes, \n",
    "            logger, kl_weight = 1, user_lr = None, log_step_size = 1):\n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(num_epochs)):  # Example: Number of epochs\n",
    "        loss_all, loss_base, loss_kl = 0, 0, 0\n",
    "        #print_user_params(dataloader)# see if values change\n",
    "        for batch in dataloader:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            timestamps, item_recom, labels, means, logvar, idx = batch\n",
    "            timestamps, item_recom, labels, means, logvar = timestamps.to(device), item_recom.to(device), labels.to(device), means.to(device), logvar.to(device)\n",
    "            \n",
    "            means.retain_grad()\n",
    "            logvar.retain_grad()\n",
    "\n",
    "            variances = torch.exp(logvar)\n",
    "            user_state = means + variances*torch.randn((1, state_size))\n",
    "            #delta_from_previous = torch.cat([torch.zeros((timestamps.size(0),1)), timestamps[:,1:] - timestamps[:,:-1]], dim=1)\n",
    "            \n",
    "            curr_loss_base = train_1_path(model=model, user_state=user_state, timestamps=timestamps, items=item_recom, labels=labels,  \n",
    "                         loss_func=loss_func,num_classes= num_classes)\n",
    "            curr_loss_kl = kl_weight * torch.sum(loss_func_kl(means, variances))#.view(1,-1)\n",
    "\n",
    "            curr_loss_all = curr_loss_kl + curr_loss_base\n",
    "            curr_loss_all.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #logging\n",
    "            loss_all += curr_loss_all.item()\n",
    "            loss_base += curr_loss_base.item()\n",
    "            loss_kl += curr_loss_kl.item()\n",
    "            # maybe need to optim user_mean, user_var separate because of torch..\n",
    "            if user_lr:\n",
    "                with torch.no_grad():\n",
    "                    means -= user_lr * means.grad\n",
    "                    logvar -= user_lr * logvar.grad  \n",
    "                means.grad.zero_()\n",
    "                logvar.grad.zero_()\n",
    "                \n",
    "                dataloader.dataset.Update_user_params(means.detach(), logvar.detach(), idx)\n",
    "        if epoch % log_step_size == 0:\n",
    "            logger(loss_all, loss_base, loss_kl)\n",
    "    logger(loss_all, loss_base, loss_kl)# log at the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_func(loss_all, loss_base, loss_kl):\n",
    "    print(\"loss_all: \", loss_all, \"\\tloss_base: \",loss_base, \"\\loss_kl: \",loss_kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  tensor([[-1.6682,  1.0347]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.5324,  0.0204]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[0.9434, 0.3297]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[0.2264, 0.6793]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.4827, -0.7810]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.7085,  0.9509]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[ 0.1913, -0.9979]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.3750,  0.5932]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.3347,  0.5144]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[ 1.3193, -0.9432]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.9807,  0.4182]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-1.2250, -0.9406]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-1.1417,  1.6132]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.3386,  0.7236]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.3777,  0.8752]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.5233, -1.1403]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.8823,  0.6713]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[0.1240, 0.8507]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.5567,  0.6752]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-1.0781, -1.2146]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.3341, -0.9852]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[0.9213, 0.8606]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print_user_params(dataloader, print_var = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:28,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  56.35666036605835 \tloss_base:  20.88695991039276 \\loss_kl:  35.46969974040985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:04<00:32,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  36.44455337524414 \tloss_base:  20.79441547393799 \\loss_kl:  15.650138258934021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:18<01:32,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  31.621041774749756 \tloss_base:  20.79441547393799 \\loss_kl:  10.82662644982338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:24<00:54,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  28.93181085586548 \tloss_base:  20.79441547393799 \\loss_kl:  8.137395441532135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:32<00:47,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  27.16498589515686 \tloss_base:  20.79441547393799 \\loss_kl:  6.370570197701454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:42<00:44,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  25.92131769657135 \tloss_base:  20.79441547393799 \\loss_kl:  5.126902222633362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:51<00:31,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  25.012293100357056 \tloss_base:  20.79441547393799 \\loss_kl:  4.217877812683582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [00:58<00:21,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  24.331183075904846 \tloss_base:  20.79441547393799 \\loss_kl:  3.5367674827575684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:09<00:20,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  23.81112277507782 \tloss_base:  20.79441547393799 \\loss_kl:  3.0167068913578987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [01:16<00:06,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  23.407631278038025 \tloss_base:  20.79441547393799 \\loss_kl:  2.613215833902359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:22<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all:  23.147793531417847 \tloss_base:  20.79441547393799 \\loss_kl:  2.353378064930439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, dataloader=dataloader, num_epochs =50, device = device, loss_func= loss_func, \n",
    "                loss_func_kl = kl_loss, kl_weight= 0.01, user_lr = 0.03,\n",
    "                optimizer=optimizer, num_classes=num_interaction_types, logger = logging_func,\n",
    "                state_size = state_size, log_step_size= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  tensor([[0.2057, 0.0719]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.6439, -0.5942]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[ 0.0416, -0.2172]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.8083, -0.6009]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.0824,  0.1908]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.8737, -1.2611]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.2490,  0.3518]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.7939, -0.5914]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.2139,  0.0912]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-1.3269, -1.1168]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.0728, -0.2148]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.5818, -0.5843]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.0730,  0.1122]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.5734, -1.1186]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.1214,  0.1472]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-1.2145, -1.3186]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.3638,  0.2257]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.8781, -0.6842]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.1053, -0.1703]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.9711, -0.5807]], grad_fn=<StackBackward0>)\n",
      "means:  tensor([[-0.1924,  0.1464]], grad_fn=<StackBackward0>)\n",
      "logvar:  tensor([[-0.6622, -0.5847]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print_user_params(dataloader, print_var = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
