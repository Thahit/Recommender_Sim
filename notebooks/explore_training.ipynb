{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "# Add the parent directory to the sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "#import simtrain\n",
    "from simtrain.sim_models_new import User_simmulation_Model\n",
    "from simtrain import SETTINGS_POLIMI as SETTINGS, process_dat\n",
    "from simtrain.Dataset import CustomDataset\n",
    "from simtrain.train import train\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import ast\n",
    "\n",
    "import paths\n",
    "from os.path import join\n",
    "import pytorch_warmup as warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = 7\n",
    "num_items_per_recom = 2\n",
    "num_interaction_types = 2\n",
    "recom_dim = 1\n",
    "num_users = 11\n",
    "min_inter = 2\n",
    "max_inter = 4\n",
    "state_size = SETTINGS.STATE_SIZE\n",
    "experiment_name = \"testing2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# generate toy data\\ndata = []\\nfor user in range(num_users):\\n    num_interactions_now = random.randint(a=min_inter, b=max_inter)\\n    new = {\\n        \\'item_ids\\': torch.randint(low=1, high=num_items, size=(num_interactions_now, \\n        num_items_per_recom, recom_dim)).to(torch.float32),\\n        \\'timestamps\\': torch.sort(torch.FloatTensor(num_interactions_now).uniform_(0, 1.))[0].to(torch.float32),\\n        \\'interaction_types\\': torch.randint(low=0, high=num_interaction_types-1, \\n        size=(num_interactions_now, num_items_per_recom)),\\n        \"user_means\": torch.randn((state_size), requires_grad=True).to(torch.float32),\\n        \"user_vars_log\": torch.randn((state_size), requires_grad=True).to(torch.float32),\\n    }\\n    data.append(new)\\n\\n\\n# Create the dataset\\ndataset = CustomDataset(data)\\n\\n# Example usage with DataLoader\\ndataloader = DataLoader(dataset, batch_size=1, shuffle=True)# can only do batchsize 1\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# generate toy data\n",
    "data = []\n",
    "for user in range(num_users):\n",
    "    num_interactions_now = random.randint(a=min_inter, b=max_inter)\n",
    "    new = {\n",
    "        'item_ids': torch.randint(low=1, high=num_items, size=(num_interactions_now, \n",
    "        num_items_per_recom, recom_dim)).to(torch.float32),\n",
    "        'timestamps': torch.sort(torch.FloatTensor(num_interactions_now).uniform_(0, 1.))[0].to(torch.float32),\n",
    "        'interaction_types': torch.randint(low=0, high=num_interaction_types-1, \n",
    "        size=(num_interactions_now, num_items_per_recom)),\n",
    "        \"user_means\": torch.randn((state_size), requires_grad=True).to(torch.float32),\n",
    "        \"user_vars_log\": torch.randn((state_size), requires_grad=True).to(torch.float32),\n",
    "    }\n",
    "    data.append(new)\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "dataset = CustomDataset(data)\n",
    "\n",
    "# Example usage with DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)# can only do batchsize 1\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_dat, stg = process_dat.load_dat(paths.cw_stages[\\'output_new\\'][\\'train\\'], new_data=True)\\n\\nprint(stg)\\n\\ndef convert_string_to_double_list(s):\\n    return ast.literal_eval(s)\\n\\n# Apply the custom function\\ntrain_dat[\\'item_ids\\'] = train_dat[\\'item_ids\\'].apply(convert_string_to_double_list)\\ntrain_dat[\\'user_means\\'] = train_dat[\\'user_means\\'].apply(convert_string_to_double_list)\\ntrain_dat[\\'user_vars_log\\'] = train_dat[\\'user_vars_log\\'].apply(convert_string_to_double_list)\\ntrain_dat[\\'timestamps\\'] = train_dat[\\'timestamps\\'].apply(convert_string_to_double_list)\\ntrain_dat[\\'interaction_types\\'] = train_dat[\\'interaction_types\\'].apply(convert_string_to_double_list)\\n\\nprint(\"len: \", len(train_dat))\\nlist_of_dicts = train_dat.to_dict(orient=\\'records\\')\\n\\ntrain_dat.head()\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataset from processed data\n",
    "'''\n",
    "train_dat, stg = process_dat.load_dat(paths.cw_stages['output_new']['train'], new_data=True)\n",
    "\n",
    "print(stg)\n",
    "\n",
    "def convert_string_to_double_list(s):\n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "# Apply the custom function\n",
    "train_dat['item_ids'] = train_dat['item_ids'].apply(convert_string_to_double_list)\n",
    "train_dat['user_means'] = train_dat['user_means'].apply(convert_string_to_double_list)\n",
    "train_dat['user_vars_log'] = train_dat['user_vars_log'].apply(convert_string_to_double_list)\n",
    "train_dat['timestamps'] = train_dat['timestamps'].apply(convert_string_to_double_list)\n",
    "train_dat['interaction_types'] = train_dat['interaction_types'].apply(convert_string_to_double_list)\n",
    "\n",
    "print(\"len: \", len(train_dat))\n",
    "list_of_dicts = train_dat.to_dict(orient='records')\n",
    "\n",
    "train_dat.head()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = torch.load(join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"data.h5\"))\n",
    "list_of_dicts = checkpoint['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = CustomDataset(list_of_dicts[:50])\n",
    "# Example usage with DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)# can only do batchsize 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0417], dtype=torch.float64)\n",
      "tensor([69.3333], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def test_timestamps(dataloader):\n",
    "    smallest = float(\"inf\")\n",
    "    biggest = -1\n",
    "    for batch in dataloader:\n",
    "        timestamps, items, labels, means, var, idx = batch\n",
    "        last = timestamps[0]\n",
    "        smallest = min(smallest, last)\n",
    "        biggest = max(biggest, timestamps[-1])\n",
    "        for i in range(1,len(timestamps)):\n",
    "            if timestamps[i] <= last:\n",
    "                print(\"error, current: \", timestamps[i], \"\\tlast\", last)\n",
    "    print(smallest), print(biggest)\n",
    "    return biggest\n",
    "\n",
    "max_time = test_timestamps(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps: [tensor([2.2500], dtype=torch.float64), tensor([12.3333], dtype=torch.float64), tensor([26.2083], dtype=torch.float64), tensor([39.2083], dtype=torch.float64), tensor([39.2708], dtype=torch.float64), tensor([47.3750], dtype=torch.float64), tensor([49.3542], dtype=torch.float64)]\n",
      "item_recom: [[tensor([14]), tensor([96]), tensor([96]), tensor([14]), tensor([14]), tensor([14]), tensor([96]), tensor([14])], [tensor([109]), tensor([109]), tensor([109])], [tensor([219]), tensor([58]), tensor([273]), tensor([10])], [tensor([16]), tensor([219]), tensor([10]), tensor([236]), tensor([236]), tensor([219]), tensor([58]), tensor([10]), tensor([58])], [tensor([254]), tensor([31])], [tensor([16]), tensor([16]), tensor([16])], [tensor([109]), tensor([109]), tensor([109]), tensor([109]), tensor([109])]]\n",
      "Labels: [[tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([1]), tensor([0]), tensor([0])], [tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])]]\n",
      "means: [tensor([0.0462], dtype=torch.float64), tensor([-0.0023], dtype=torch.float64), tensor([0.0728], dtype=torch.float64), tensor([0.1846], dtype=torch.float64), tensor([-0.0189], dtype=torch.float64), tensor([-0.0549], dtype=torch.float64), tensor([0.0969], dtype=torch.float64), tensor([-0.0393], dtype=torch.float64)]\n",
      "log_var: [tensor([-0.0751], dtype=torch.float64), tensor([-0.0437], dtype=torch.float64), tensor([-0.0784], dtype=torch.float64), tensor([-0.0905], dtype=torch.float64), tensor([-0.0380], dtype=torch.float64), tensor([-0.0617], dtype=torch.float64), tensor([-0.0841], dtype=torch.float64), tensor([-0.0301], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    timestamps, items, labels, means, var, idx = batch\n",
    "    print('Timestamps:', timestamps#, \"\\n dtype: \", timestamps.dtype\n",
    "          )\n",
    "    print('item_recom:', items#, \"\\n dtype: \", items.dtype\n",
    "          )\n",
    "    print('Labels:', labels#, \"\\n dtype: \", labels.dtype\n",
    "          )\n",
    "    print('means:', means#, \"\\n dtype: \", means.dtype\n",
    "          )\n",
    "    print('log_var:', var#, \"\\n dtype: \", var.dtype\n",
    "          )\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter dicts\n",
    "width= 10\n",
    "user_state_dict = {\"model_hyp\": {\"layer_width\": [width, width, width]}}\n",
    "intensity_state_dict = {\"model_hyp\": {\"user_model_hyp\": {\"layer_width\": [width, width, 3],\n",
    "                                                         \"noise\": 0},\n",
    "                                          \"global_model_hyp\": {\"layer_width\": [width, 3]}}\n",
    "                            }\n",
    "interaction_state_dict = {\"model_hyp\": {\"layer_width\": [width, width ,width]}\n",
    "                            }\n",
    "jump_state_dict = {\"model_hyp\": {\"layer_width\": [width, width]}\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "hyperparameter_dict = {\"state_size\": state_size, \"state_model\": user_state_dict, \"num_interaction_outcomes\": num_interaction_types,\n",
    "                           \"intensity_model\": intensity_state_dict, \"num_recom\" : num_items_per_recom,\n",
    "                            \"recom_dim\":recom_dim, \"interaction_model\": interaction_state_dict,\n",
    "                            \"jump_model\": jump_state_dict}\n",
    "model = User_simmulation_Model(hyperparameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "path = join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"user_model.h5\")\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_func = nn.functional.mse_loss\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "def kl_divergence(mu1, sigma1, mu2, sigma2):\n",
    "    \"\"\"\n",
    "    Compute the KL divergence between two normal distributions N(mu1, sigma1^2) and N(mu2, sigma2^2).\n",
    "\n",
    "    Args:\n",
    "        mu1 (Tensor): Mean of the first distribution.\n",
    "        sigma1 (Tensor): Standard deviation of the first distribution.\n",
    "        mu2 (Tensor): Mean of the second distribution.\n",
    "        sigma2 (Tensor): Standard deviation of the second distribution.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: KL divergence.\n",
    "    \"\"\"\n",
    "    kl_div = torch.log(sigma2 / sigma1) + ((sigma1 ** 2 + (mu1 - mu2) ** 2) / (2 * sigma2 ** 2)) - 0.5\n",
    "    return kl_div\n",
    "\n",
    "def kl_divergence_to_standard_normal(mu, sigma):\n",
    "    \"\"\"\n",
    "    Compute the KL divergence from a normal distribution N(mu, sigma^2) to the standard normal distribution N(0, 1).\n",
    "\n",
    "    Args:\n",
    "        mu (Tensor): Mean of the normal distribution.\n",
    "        sigma (Tensor): Standard deviation of the normal distribution.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: KL divergence.\n",
    "    \"\"\"\n",
    "    sigma2 = sigma ** 2\n",
    "    kl_div = 0.5 * (sigma2 + mu ** 2 - torch.log(sigma2) - 1)\n",
    "    return kl_div\n",
    "\n",
    "def kl_loss(mu, sigma):\n",
    "    return kl_divergence(mu, sigma, 0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_user_params(datadataloader, print_var = False, num_examples=5):\n",
    "    i = 0\n",
    "    for batch in dataloader:\n",
    "        timestamps, item_recom, labels, means, logvar, idx = batch\n",
    "        print(\"means: \", means)\n",
    "        if (print_var):\n",
    "            print(\"logvar: \", logvar)\n",
    "        i+=1\n",
    "        if i >= num_examples:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_func(loss_all, loss_base, loss_kl, loss_intensity):\n",
    "    print(\"loss_all: \", loss_all, \"\\tloss_base: \",loss_base, \"\\tloss_kl: \",loss_kl, \"\\tloss_intensity: \",loss_intensity, \"\\tlog of the loss: \", math.log(loss_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "warmup_period = len(dataset)\n",
    "num_steps = num_epochs*len(dataset) -warmup_period\n",
    "num_iter_til_first_restart = num_steps//2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01,\n",
    "                        weight_decay=1e-8)\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=num_iter_til_first_restart, T_mult=1, eta_min=1e-4)\n",
    "\n",
    "warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  [tensor([-0.0869], dtype=torch.float64), tensor([-0.0108], dtype=torch.float64), tensor([-0.1787], dtype=torch.float64), tensor([-0.2017], dtype=torch.float64), tensor([0.0532], dtype=torch.float64), tensor([-0.0692], dtype=torch.float64), tensor([-0.1069], dtype=torch.float64), tensor([-0.2690], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.0146], dtype=torch.float64), tensor([-0.0804], dtype=torch.float64), tensor([-0.0351], dtype=torch.float64), tensor([-0.1144], dtype=torch.float64), tensor([-0.0248], dtype=torch.float64), tensor([-0.1740], dtype=torch.float64), tensor([-0.0318], dtype=torch.float64), tensor([-0.0574], dtype=torch.float64)]\n",
      "means:  [tensor([0.0049], dtype=torch.float64), tensor([-0.0388], dtype=torch.float64), tensor([-0.1131], dtype=torch.float64), tensor([-0.2373], dtype=torch.float64), tensor([-0.0335], dtype=torch.float64), tensor([0.0196], dtype=torch.float64), tensor([-0.1732], dtype=torch.float64), tensor([-0.1760], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.0210], dtype=torch.float64), tensor([-0.1315], dtype=torch.float64), tensor([-0.0277], dtype=torch.float64), tensor([-0.1270], dtype=torch.float64), tensor([-0.0168], dtype=torch.float64), tensor([-0.0684], dtype=torch.float64), tensor([6.1983e-05], dtype=torch.float64), tensor([0.0220], dtype=torch.float64)]\n",
      "means:  [tensor([0.0252], dtype=torch.float64), tensor([-0.2481], dtype=torch.float64), tensor([-0.1521], dtype=torch.float64), tensor([-0.2318], dtype=torch.float64), tensor([-0.0640], dtype=torch.float64), tensor([-0.0022], dtype=torch.float64), tensor([-0.1841], dtype=torch.float64), tensor([-0.0725], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.0077], dtype=torch.float64), tensor([-0.1854], dtype=torch.float64), tensor([-0.0352], dtype=torch.float64), tensor([-0.0081], dtype=torch.float64), tensor([0.0209], dtype=torch.float64), tensor([-0.0748], dtype=torch.float64), tensor([-0.0295], dtype=torch.float64), tensor([-0.0351], dtype=torch.float64)]\n",
      "means:  [tensor([-0.0295], dtype=torch.float64), tensor([-0.0876], dtype=torch.float64), tensor([-0.0725], dtype=torch.float64), tensor([0.0030], dtype=torch.float64), tensor([0.0324], dtype=torch.float64), tensor([0.0054], dtype=torch.float64), tensor([-0.0827], dtype=torch.float64), tensor([-0.0816], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.0341], dtype=torch.float64), tensor([-0.0348], dtype=torch.float64), tensor([-0.1016], dtype=torch.float64), tensor([-0.0503], dtype=torch.float64), tensor([-0.0270], dtype=torch.float64), tensor([0.0125], dtype=torch.float64), tensor([-0.1046], dtype=torch.float64), tensor([-0.0460], dtype=torch.float64)]\n",
      "means:  [tensor([0.0091], dtype=torch.float64), tensor([-0.0680], dtype=torch.float64), tensor([-0.0352], dtype=torch.float64), tensor([-0.0134], dtype=torch.float64), tensor([0.0264], dtype=torch.float64), tensor([-0.0155], dtype=torch.float64), tensor([-0.0840], dtype=torch.float64), tensor([-0.0864], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.0607], dtype=torch.float64), tensor([-0.0370], dtype=torch.float64), tensor([-0.0259], dtype=torch.float64), tensor([-0.0539], dtype=torch.float64), tensor([-0.0444], dtype=torch.float64), tensor([-0.0306], dtype=torch.float64), tensor([-0.0115], dtype=torch.float64), tensor([-0.0139], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "print_user_params(dataloader, print_var = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/home/thahit/github/Recommender_Sim/simtrain/train.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_pred = nn.functional.log_softmax(y_pred)\n",
      "  0%|          | 0/5 [00:04<?, ?it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_6509/1289622088.py\", line 5, in <module>\n",
      "    state_size=state_size,max_time=max_time, log_step_size=1, warmup_scheduler = warmup_scheduler,\n",
      "  File \"/home/thahit/github/Recommender_Sim/simtrain/train.py\", line 94, in train\n",
      "    means.zero_grad()\n",
      "AttributeError: 'Tensor' object has no attribute 'zero_grad'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2098, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'AttributeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/thahit/anaconda3/envs/WW/lib/python3.7/posixpath.py\", line 415, in _joinrealpath\n",
      "    name, _, rest = rest.partition(sep)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6509/1289622088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwarmup_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 \u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_step_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarmup_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                 )\n",
      "\u001b[0;32m~/github/Recommender_Sim/simtrain/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, dataloader, num_epochs, state_size, loss_func, loss_func_kl, optimizer, num_classes, logger, max_time, lr_scheduler, warmup_scheduler, kl_weight, user_lr, log_step_size, warmup_period)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;31m#print(means)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mlogvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'zero_grad'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2097\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AttributeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2101\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "train(model, dataloader=dataloader, num_epochs=num_epochs, device=device, loss_func=loss_func, \n",
    "                loss_func_kl=kl_divergence_to_standard_normal, kl_weight=1., user_lr=0.1,\n",
    "                optimizer=optimizer, lr_scheduler=lr_scheduler, num_classes=num_interaction_types, \n",
    "                logger=logging_func,warmup_period=warmup_period,\n",
    "                state_size=state_size,max_time=max_time, log_step_size=1, warmup_scheduler = warmup_scheduler,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  [tensor([0.0149], dtype=torch.float64), tensor([-0.0143], dtype=torch.float64), tensor([0.0468], dtype=torch.float64), tensor([0.0425], dtype=torch.float64), tensor([0.0993], dtype=torch.float64), tensor([0.0387], dtype=torch.float64), tensor([-0.0228], dtype=torch.float64), tensor([-0.0680], dtype=torch.float64)]\n",
      "logvar:  [tensor([0.1817], dtype=torch.float64), tensor([-0.0555], dtype=torch.float64), tensor([-0.0278], dtype=torch.float64), tensor([-0.3957], dtype=torch.float64), tensor([0.0319], dtype=torch.float64), tensor([-0.1186], dtype=torch.float64), tensor([0.1501], dtype=torch.float64), tensor([0.3147], dtype=torch.float64)]\n",
      "means:  [tensor([0.0865], dtype=torch.float64), tensor([-0.1777], dtype=torch.float64), tensor([0.0748], dtype=torch.float64), tensor([-0.1917], dtype=torch.float64), tensor([-0.0618], dtype=torch.float64), tensor([0.0318], dtype=torch.float64), tensor([0.0258], dtype=torch.float64), tensor([0.0558], dtype=torch.float64)]\n",
      "logvar:  [tensor([0.0162], dtype=torch.float64), tensor([-0.0764], dtype=torch.float64), tensor([-0.0083], dtype=torch.float64), tensor([-0.2836], dtype=torch.float64), tensor([0.0326], dtype=torch.float64), tensor([0.0097], dtype=torch.float64), tensor([0.0327], dtype=torch.float64), tensor([-0.0345], dtype=torch.float64)]\n",
      "means:  [tensor([-0.0916], dtype=torch.float64), tensor([0.1678], dtype=torch.float64), tensor([0.0806], dtype=torch.float64), tensor([-0.1010], dtype=torch.float64), tensor([0.1379], dtype=torch.float64), tensor([-0.0929], dtype=torch.float64), tensor([0.0877], dtype=torch.float64), tensor([0.0377], dtype=torch.float64)]\n",
      "logvar:  [tensor([0.0367], dtype=torch.float64), tensor([-0.2150], dtype=torch.float64), tensor([0.0098], dtype=torch.float64), tensor([0.0333], dtype=torch.float64), tensor([-0.1975], dtype=torch.float64), tensor([0.0259], dtype=torch.float64), tensor([-0.0390], dtype=torch.float64), tensor([0.0046], dtype=torch.float64)]\n",
      "means:  [tensor([-0.0382], dtype=torch.float64), tensor([0.0069], dtype=torch.float64), tensor([-0.0607], dtype=torch.float64), tensor([0.0900], dtype=torch.float64), tensor([0.1551], dtype=torch.float64), tensor([-0.1553], dtype=torch.float64), tensor([0.0447], dtype=torch.float64), tensor([-0.1774], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.2697], dtype=torch.float64), tensor([-0.0378], dtype=torch.float64), tensor([-0.1069], dtype=torch.float64), tensor([-0.3420], dtype=torch.float64), tensor([-0.0520], dtype=torch.float64), tensor([0.0276], dtype=torch.float64), tensor([-0.0699], dtype=torch.float64), tensor([0.1175], dtype=torch.float64)]\n",
      "means:  [tensor([0.0431], dtype=torch.float64), tensor([-0.1170], dtype=torch.float64), tensor([-0.0166], dtype=torch.float64), tensor([0.3163], dtype=torch.float64), tensor([0.3602], dtype=torch.float64), tensor([-0.0831], dtype=torch.float64), tensor([0.0140], dtype=torch.float64), tensor([-0.2879], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.2145], dtype=torch.float64), tensor([0.0386], dtype=torch.float64), tensor([0.0833], dtype=torch.float64), tensor([0.4553], dtype=torch.float64), tensor([-0.1556], dtype=torch.float64), tensor([0.0960], dtype=torch.float64), tensor([0.0055], dtype=torch.float64), tensor([0.1462], dtype=torch.float64)]\n",
      "means:  [tensor([0.1098], dtype=torch.float64), tensor([-0.2381], dtype=torch.float64), tensor([-0.0391], dtype=torch.float64), tensor([0.4226], dtype=torch.float64), tensor([0.0188], dtype=torch.float64), tensor([0.0730], dtype=torch.float64), tensor([-0.0927], dtype=torch.float64), tensor([-0.2449], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.2163], dtype=torch.float64), tensor([-0.0817], dtype=torch.float64), tensor([0.0725], dtype=torch.float64), tensor([0.1490], dtype=torch.float64), tensor([-0.0290], dtype=torch.float64), tensor([0.0149], dtype=torch.float64), tensor([-0.0159], dtype=torch.float64), tensor([-0.2935], dtype=torch.float64)]\n",
      "means:  [tensor([0.0514], dtype=torch.float64), tensor([-0.0856], dtype=torch.float64), tensor([-0.0359], dtype=torch.float64), tensor([0.2213], dtype=torch.float64), tensor([0.0791], dtype=torch.float64), tensor([0.0265], dtype=torch.float64), tensor([-0.0078], dtype=torch.float64), tensor([-0.1508], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.0473], dtype=torch.float64), tensor([0.0904], dtype=torch.float64), tensor([0.0182], dtype=torch.float64), tensor([0.2260], dtype=torch.float64), tensor([-0.1503], dtype=torch.float64), tensor([-0.0059], dtype=torch.float64), tensor([-0.0028], dtype=torch.float64), tensor([0.0747], dtype=torch.float64)]\n",
      "means:  [tensor([-0.0629], dtype=torch.float64), tensor([0.0297], dtype=torch.float64), tensor([0.0950], dtype=torch.float64), tensor([0.1668], dtype=torch.float64), tensor([0.2311], dtype=torch.float64), tensor([-0.0199], dtype=torch.float64), tensor([0.0541], dtype=torch.float64), tensor([-0.1571], dtype=torch.float64)]\n",
      "logvar:  [tensor([0.1149], dtype=torch.float64), tensor([-0.0245], dtype=torch.float64), tensor([-0.1048], dtype=torch.float64), tensor([-0.3196], dtype=torch.float64), tensor([-0.2237], dtype=torch.float64), tensor([0.1189], dtype=torch.float64), tensor([-0.0872], dtype=torch.float64), tensor([0.0221], dtype=torch.float64)]\n",
      "means:  [tensor([-0.1654], dtype=torch.float64), tensor([0.0151], dtype=torch.float64), tensor([0.0555], dtype=torch.float64), tensor([0.0179], dtype=torch.float64), tensor([0.0351], dtype=torch.float64), tensor([0.0753], dtype=torch.float64), tensor([-0.0776], dtype=torch.float64), tensor([-0.0882], dtype=torch.float64)]\n",
      "logvar:  [tensor([0.0842], dtype=torch.float64), tensor([-0.1430], dtype=torch.float64), tensor([-0.0566], dtype=torch.float64), tensor([0.0496], dtype=torch.float64), tensor([0.0012], dtype=torch.float64), tensor([0.0963], dtype=torch.float64), tensor([-0.2294], dtype=torch.float64), tensor([-0.1231], dtype=torch.float64)]\n",
      "means:  [tensor([0.1249], dtype=torch.float64), tensor([-0.1292], dtype=torch.float64), tensor([-0.0440], dtype=torch.float64), tensor([0.1998], dtype=torch.float64), tensor([0.0587], dtype=torch.float64), tensor([0.0197], dtype=torch.float64), tensor([-0.0262], dtype=torch.float64), tensor([-0.1064], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.1422], dtype=torch.float64), tensor([-0.1078], dtype=torch.float64), tensor([0.0986], dtype=torch.float64), tensor([0.0833], dtype=torch.float64), tensor([0.0237], dtype=torch.float64), tensor([-0.0201], dtype=torch.float64), tensor([0.0267], dtype=torch.float64), tensor([0.1995], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "print_user_params(dataloader, print_var = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saved_models_polimi/accordion/user_model.h5'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SETTINGS.filepaths['user_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "path = join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"user_model.h5\")\n",
    "\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data(changes during training)\n",
    "path = join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"data.h5\")\n",
    "torch.save({\n",
    "    'data': dataloader.dataset.data,\n",
    "}, path# 'saved_models_polimi/data.h5'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
