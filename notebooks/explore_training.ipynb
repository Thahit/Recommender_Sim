{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "# Add the parent directory to the sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "#import simtrain\n",
    "from simtrain.sim_models_new import User_simmulation_Model\n",
    "from simtrain import SETTINGS_POLIMI as SETTINGS\n",
    "from simtrain import explore_models, process_dat\n",
    "import simtrain.utils as utils\n",
    "from simtrain.Dataset import CustomDataset\n",
    "from simtrain.train import train\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import ast\n",
    "\n",
    "import paths\n",
    "from os.path import join\n",
    "import pytorch_warmup as warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_items = 7\n",
    "#num_items_per_recom = 2\n",
    "num_interaction_types = 2\n",
    "recom_dim = 1\n",
    "#num_users = 11\n",
    "#min_inter = 2\n",
    "#max_inter = 4\n",
    "state_size = SETTINGS.STATE_SIZE\n",
    "subset = 50 # make data smaller\n",
    "experiment_name = \"testing2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_dat, stg = process_dat.load_dat(paths.cw_stages[\\'output_new\\'][\\'train\\'], new_data=True)\\n\\nprint(stg)\\n\\ndef convert_string_to_double_list(s):\\n    return ast.literal_eval(s)\\n\\n# Apply the custom function\\ntrain_dat[\\'item_ids\\'] = train_dat[\\'item_ids\\'].apply(convert_string_to_double_list)\\ntrain_dat[\\'user_means\\'] = train_dat[\\'user_means\\'].apply(convert_string_to_double_list)\\ntrain_dat[\\'user_vars_log\\'] = train_dat[\\'user_vars_log\\'].apply(convert_string_to_double_list)\\ntrain_dat[\\'timestamps\\'] = train_dat[\\'timestamps\\'].apply(convert_string_to_double_list)\\ntrain_dat[\\'interaction_types\\'] = train_dat[\\'interaction_types\\'].apply(convert_string_to_double_list)\\n\\nprint(\"len: \", len(train_dat))\\nlist_of_dicts = train_dat.to_dict(orient=\\'records\\')\\nlist_of_dicts = list_of_dicts[:subset]\\ntrain_dat.head()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataset from processed data\n",
    "'''\n",
    "train_dat, stg = process_dat.load_dat(paths.cw_stages['output_new']['train'], new_data=True)\n",
    "\n",
    "print(stg)\n",
    "\n",
    "def convert_string_to_double_list(s):\n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "# Apply the custom function\n",
    "train_dat['item_ids'] = train_dat['item_ids'].apply(convert_string_to_double_list)\n",
    "train_dat['user_means'] = train_dat['user_means'].apply(convert_string_to_double_list)\n",
    "train_dat['user_vars_log'] = train_dat['user_vars_log'].apply(convert_string_to_double_list)\n",
    "train_dat['timestamps'] = train_dat['timestamps'].apply(convert_string_to_double_list)\n",
    "train_dat['interaction_types'] = train_dat['interaction_types'].apply(convert_string_to_double_list)\n",
    "\n",
    "print(\"len: \", len(train_dat))\n",
    "list_of_dicts = train_dat.to_dict(orient='records')\n",
    "list_of_dicts = list_of_dicts[:subset]\n",
    "train_dat.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = torch.load(join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"data.h5\"))\n",
    "list_of_dicts = checkpoint['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef adjust_hidden_dim(data_dict, state_size):\\n    # just to jumstart experiments should be deleted at the end\\n    for row in list_of_dicts:\\n        if row[\"user_means\"] > state_size:\\n            row[\"user_means\"] = row[\"user_means\"][:state_size]\\n            row[\"user_vars_log\"] = row[\"user_vars_log\"][:state_size]\\n        elif row[\"user_means\"] > state_size:\\n\\n\\nadjust_hidden_dim(list_of_dicts, state_size)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def adjust_hidden_dim(data_dict, state_size):\n",
    "    # just to jumstart experiments should be deleted at the end\n",
    "    for row in list_of_dicts:\n",
    "        if row[\"user_means\"] > state_size:\n",
    "            row[\"user_means\"] = row[\"user_means\"][:state_size]\n",
    "            row[\"user_vars_log\"] = row[\"user_vars_log\"][:state_size]\n",
    "        elif row[\"user_means\"] > state_size:\n",
    "\n",
    "\n",
    "adjust_hidden_dim(list_of_dicts, state_size)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = CustomDataset(list_of_dicts) # [:50]\n",
    "# Example usage with DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)# can only do batchsize 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0417], dtype=torch.float64)\n",
      "tensor([69.3333], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def test_timestamps(dataloader):\n",
    "    smallest = float(\"inf\")\n",
    "    biggest = -1\n",
    "    for batch in dataloader:\n",
    "        timestamps, items, labels, means, var, idx = batch\n",
    "        last = timestamps[0]\n",
    "        smallest = min(smallest, last)\n",
    "        biggest = max(biggest, timestamps[-1])\n",
    "        for i in range(1,len(timestamps)):\n",
    "            if timestamps[i] <= last:\n",
    "                print(\"error, current: \", timestamps[i], \"\\tlast\", last)\n",
    "    print(smallest), print(biggest)\n",
    "    return biggest\n",
    "\n",
    "max_time = test_timestamps(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps: [tensor([5.], dtype=torch.float64), tensor([5.0417], dtype=torch.float64), tensor([5.0833], dtype=torch.float64), tensor([41.0833], dtype=torch.float64)]\n",
      "item_recom: [[tensor([53]), tensor([50]), tensor([217]), tensor([205]), tensor([66]), tensor([53]), tensor([199]), tensor([134]), tensor([2]), tensor([53]), tensor([66]), tensor([50]), tensor([199]), tensor([77]), tensor([134]), tensor([77]), tensor([2]), tensor([134]), tensor([77]), tensor([50]), tensor([66]), tensor([199]), tensor([217]), tensor([205]), tensor([205]), tensor([217]), tensor([2])], [tensor([168]), tensor([205]), tensor([217]), tensor([138]), tensor([53]), tensor([166]), tensor([203]), tensor([73]), tensor([138]), tensor([168]), tensor([159]), tensor([66]), tensor([268]), tensor([297]), tensor([66]), tensor([261]), tensor([178]), tensor([159]), tensor([178]), tensor([203]), tensor([203]), tensor([159]), tensor([168]), tensor([138]), tensor([217]), tensor([205]), tensor([53]), tensor([57]), tensor([297]), tensor([50]), tensor([57]), tensor([53]), tensor([233]), tensor([50]), tensor([2]), tensor([77]), tensor([199]), tensor([66]), tensor([53]), tensor([205]), tensor([217]), tensor([134]), tensor([205]), tensor([66]), tensor([20]), tensor([238]), tensor([60]), tensor([66]), tensor([217]), tensor([62]), tensor([199]), tensor([50]), tensor([53]), tensor([138]), tensor([34]), tensor([227]), tensor([17]), tensor([217]), tensor([205]), tensor([50]), tensor([134]), tensor([2]), tensor([153]), tensor([297]), tensor([192]), tensor([154]), tensor([153]), tensor([159]), tensor([62]), tensor([138]), tensor([118]), tensor([57]), tensor([2]), tensor([159]), tensor([212]), tensor([227]), tensor([269]), tensor([190]), tensor([27]), tensor([186]), tensor([0]), tensor([282]), tensor([8]), tensor([168]), tensor([98]), tensor([203]), tensor([178]), tensor([57]), tensor([60]), tensor([20]), tensor([66]), tensor([50]), tensor([199]), tensor([77]), tensor([134]), tensor([147]), tensor([2]), tensor([51]), tensor([134]), tensor([210]), tensor([238]), tensor([110]), tensor([20]), tensor([57]), tensor([178]), tensor([89]), tensor([284]), tensor([2]), tensor([205]), tensor([203]), tensor([178]), tensor([57]), tensor([57]), tensor([217]), tensor([205]), tensor([53]), tensor([297]), tensor([77]), tensor([153]), tensor([297]), tensor([77]), tensor([199]), tensor([217]), tensor([205]), tensor([50]), tensor([168]), tensor([66]), tensor([284]), tensor([192]), tensor([217]), tensor([53]), tensor([60])], [tensor([192]), tensor([159]), tensor([53]), tensor([199]), tensor([0]), tensor([300]), tensor([138]), tensor([168]), tensor([77]), tensor([50]), tensor([178]), tensor([57]), tensor([153]), tensor([199]), tensor([205]), tensor([217]), tensor([50]), tensor([203]), tensor([205]), tensor([279]), tensor([66]), tensor([144]), tensor([297]), tensor([263]), tensor([161]), tensor([42]), tensor([70]), tensor([214]), tensor([286]), tensor([192]), tensor([110]), tensor([231]), tensor([234]), tensor([115]), tensor([126]), tensor([203]), tensor([234]), tensor([50]), tensor([77]), tensor([53]), tensor([234]), tensor([217]), tensor([50]), tensor([66]), tensor([53]), tensor([147]), tensor([66]), tensor([211]), tensor([192]), tensor([98]), tensor([231]), tensor([20]), tensor([110]), tensor([57]), tensor([217]), tensor([205]), tensor([169]), tensor([60]), tensor([191]), tensor([199]), tensor([205]), tensor([77]), tensor([2]), tensor([218]), tensor([269]), tensor([190]), tensor([3]), tensor([27]), tensor([158]), tensor([186]), tensor([125]), tensor([66]), tensor([53]), tensor([217]), tensor([50]), tensor([60]), tensor([238]), tensor([20]), tensor([60]), tensor([20]), tensor([134]), tensor([57]), tensor([195]), tensor([203]), tensor([53]), tensor([66]), tensor([50]), tensor([199]), tensor([77]), tensor([134]), tensor([2]), tensor([205]), tensor([297]), tensor([53]), tensor([205]), tensor([217]), tensor([57]), tensor([178]), tensor([57]), tensor([205]), tensor([66]), tensor([217]), tensor([217]), tensor([53]), tensor([50]), tensor([77]), tensor([66]), tensor([134]), tensor([2]), tensor([2]), tensor([110]), tensor([192]), tensor([50]), tensor([297]), tensor([66]), tensor([53]), tensor([205]), tensor([217]), tensor([138]), tensor([199]), tensor([53]), tensor([159]), tensor([178]), tensor([168]), tensor([66]), tensor([20]), tensor([238]), tensor([66]), tensor([238]), tensor([60]), tensor([60]), tensor([217]), tensor([205]), tensor([297]), tensor([153]), tensor([50]), tensor([199]), tensor([57]), tensor([138]), tensor([168]), tensor([134]), tensor([159]), tensor([192]), tensor([77]), tensor([20]), tensor([205]), tensor([53]), tensor([205]), tensor([217]), tensor([2]), tensor([217]), tensor([50]), tensor([290]), tensor([69]), tensor([192]), tensor([219]), tensor([82]), tensor([78]), tensor([212]), tensor([50]), tensor([213]), tensor([66]), tensor([53]), tensor([183])], [tensor([77]), tensor([53]), tensor([66]), tensor([89]), tensor([62]), tensor([284]), tensor([199]), tensor([205]), tensor([297]), tensor([217])]]\n",
      "Labels: [[tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])], [tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])]]\n",
      "means: [tensor([0.0005], dtype=torch.float64), tensor([-0.0005], dtype=torch.float64), tensor([-8.1689e-05], dtype=torch.float64)]\n",
      "log_var: [tensor([-0.1155], dtype=torch.float64), tensor([-0.1155], dtype=torch.float64), tensor([-0.1155], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    timestamps, items, labels, means, var, idx = batch\n",
    "    print('Timestamps:', timestamps#, \"\\n dtype: \", timestamps.dtype\n",
    "          )\n",
    "    print('item_recom:', items#, \"\\n dtype: \", items.dtype\n",
    "          )\n",
    "    print('Labels:', labels#, \"\\n dtype: \", labels.dtype\n",
    "          )\n",
    "    print('means:', means#, \"\\n dtype: \", means.dtype\n",
    "          )\n",
    "    print('log_var:', var#, \"\\n dtype: \", var.dtype\n",
    "          )\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter dicts\n",
    "width= 10\n",
    "user_state_dict = {\"model_hyp\": {\"layer_width\": [width, width, width]}}\n",
    "intensity_state_dict = {\"model_hyp\": {\"user_model_hyp\": {\"layer_width\": [width, width, 3],\n",
    "                                                         \"noise\": 0},\n",
    "                                          \"global_model_hyp\": {\"layer_width\": [width, 3]}}\n",
    "                            }\n",
    "interaction_state_dict = {\"model_hyp\": {\"layer_width\": [width, width ,width]}\n",
    "                            }\n",
    "jump_state_dict = {\"model_hyp\": {\"layer_width\": [width, width]}\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "hyperparameter_dict = {\"state_size\": state_size, \"state_model\": user_state_dict, \"num_interaction_outcomes\": num_interaction_types,\n",
    "                           \"intensity_model\": intensity_state_dict,# \"num_recom\" : num_items_per_recom,\n",
    "                            \"recom_dim\":recom_dim, \"interaction_model\": interaction_state_dict,\n",
    "                            \"jump_model\": jump_state_dict}\n",
    "model = User_simmulation_Model(hyperparameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "path = join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"user_model.h5\")\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "warmup_period = len(dataset)\n",
    "num_steps = num_epochs*len(dataset) -warmup_period\n",
    "num_iter_til_first_restart = num_steps//2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01,\n",
    "                        weight_decay=1e-8)\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=num_iter_til_first_restart, T_mult=1, eta_min=5e-5)\n",
    "\n",
    "warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  [tensor([0.0223], dtype=torch.float64), tensor([-0.0950], dtype=torch.float64), tensor([0.0211], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.1155], dtype=torch.float64), tensor([-0.1155], dtype=torch.float64), tensor([-0.1155], dtype=torch.float64)]\n",
      "means:  [tensor([2.3246e-05], dtype=torch.float64), tensor([0.0005], dtype=torch.float64), tensor([3.8117e-05], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.1211], dtype=torch.float64), tensor([0.0036], dtype=torch.float64), tensor([-0.0649], dtype=torch.float64)]\n",
      "means:  [tensor([0.0006], dtype=torch.float64), tensor([-0.0007], dtype=torch.float64), tensor([-0.0003], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.1155], dtype=torch.float64), tensor([-0.1155], dtype=torch.float64), tensor([-0.1155], dtype=torch.float64)]\n",
      "means:  [tensor([0.0003], dtype=torch.float64), tensor([-0.0004], dtype=torch.float64), tensor([-1.4478e-05], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.1155], dtype=torch.float64), tensor([-0.1155], dtype=torch.float64), tensor([-0.1155], dtype=torch.float64)]\n",
      "means:  [tensor([0.0003], dtype=torch.float64), tensor([-0.0003], dtype=torch.float64), tensor([9.6649e-05], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.1155], dtype=torch.float64), tensor([-0.1155], dtype=torch.float64), tensor([-0.1155], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "utils.print_user_params(dataloader, print_var = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/thahit/github/Recommender_Sim/simtrain/train.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_pred = nn.functional.log_softmax(y_pred)\n",
      " 10%|█         | 1/10 [14:32<2:10:51, 872.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_all: inf \tloss_base: 186.50 \tloss_kl: 596446.69 \tloss_intensity:  inf \tlog of the loss: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [15:29<2:19:28, 929.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10388/1972671877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_interaction_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwarmup_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintensity_loss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare_intensity_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 \u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_step_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarmup_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                 )\n",
      "\u001b[0;32m~/github/Recommender_Sim/simtrain/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, dataloader, num_epochs, state_size, loss_func, loss_func_kl, optimizer, num_classes, intensity_loss_func, logger, max_time, lr_scheduler, warmup_scheduler, kl_weight, user_lr, log_step_size, warmup_period)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mcurr_loss_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_loss_kl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurr_loss_base\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcurr_loss_intensity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mcurr_loss_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;32m~/anaconda3/envs/WW/lib/python3.7/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBackwardCFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FunctionBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunctionCtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_HookMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# The user should define either backward or vjp but never both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, dataloader=dataloader, num_epochs=num_epochs, device=device, loss_func=utils.loss_func, \n",
    "                loss_func_kl=utils.kl_loss, kl_weight=1., user_lr=0.1,\n",
    "                optimizer=optimizer, lr_scheduler=lr_scheduler, num_classes=num_interaction_types, \n",
    "                logger=utils.logging_func,warmup_period=warmup_period, intensity_loss_func=utils.square_intensity_loss,\n",
    "                state_size=state_size,max_time=max_time, log_step_size=1, warmup_scheduler = warmup_scheduler,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  [tensor([0.0149], dtype=torch.float64), tensor([-0.0143], dtype=torch.float64), tensor([0.0468], dtype=torch.float64), tensor([0.0425], dtype=torch.float64), tensor([0.0993], dtype=torch.float64), tensor([0.0387], dtype=torch.float64), tensor([-0.0228], dtype=torch.float64), tensor([-0.0680], dtype=torch.float64)]\n",
      "logvar:  [tensor([0.1817], dtype=torch.float64), tensor([-0.0555], dtype=torch.float64), tensor([-0.0278], dtype=torch.float64), tensor([-0.3957], dtype=torch.float64), tensor([0.0319], dtype=torch.float64), tensor([-0.1186], dtype=torch.float64), tensor([0.1501], dtype=torch.float64), tensor([0.3147], dtype=torch.float64)]\n",
      "means:  [tensor([0.0865], dtype=torch.float64), tensor([-0.1777], dtype=torch.float64), tensor([0.0748], dtype=torch.float64), tensor([-0.1917], dtype=torch.float64), tensor([-0.0618], dtype=torch.float64), tensor([0.0318], dtype=torch.float64), tensor([0.0258], dtype=torch.float64), tensor([0.0558], dtype=torch.float64)]\n",
      "logvar:  [tensor([0.0162], dtype=torch.float64), tensor([-0.0764], dtype=torch.float64), tensor([-0.0083], dtype=torch.float64), tensor([-0.2836], dtype=torch.float64), tensor([0.0326], dtype=torch.float64), tensor([0.0097], dtype=torch.float64), tensor([0.0327], dtype=torch.float64), tensor([-0.0345], dtype=torch.float64)]\n",
      "means:  [tensor([-0.0916], dtype=torch.float64), tensor([0.1678], dtype=torch.float64), tensor([0.0806], dtype=torch.float64), tensor([-0.1010], dtype=torch.float64), tensor([0.1379], dtype=torch.float64), tensor([-0.0929], dtype=torch.float64), tensor([0.0877], dtype=torch.float64), tensor([0.0377], dtype=torch.float64)]\n",
      "logvar:  [tensor([0.0367], dtype=torch.float64), tensor([-0.2150], dtype=torch.float64), tensor([0.0098], dtype=torch.float64), tensor([0.0333], dtype=torch.float64), tensor([-0.1975], dtype=torch.float64), tensor([0.0259], dtype=torch.float64), tensor([-0.0390], dtype=torch.float64), tensor([0.0046], dtype=torch.float64)]\n",
      "means:  [tensor([-0.0382], dtype=torch.float64), tensor([0.0069], dtype=torch.float64), tensor([-0.0607], dtype=torch.float64), tensor([0.0900], dtype=torch.float64), tensor([0.1551], dtype=torch.float64), tensor([-0.1553], dtype=torch.float64), tensor([0.0447], dtype=torch.float64), tensor([-0.1774], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.2697], dtype=torch.float64), tensor([-0.0378], dtype=torch.float64), tensor([-0.1069], dtype=torch.float64), tensor([-0.3420], dtype=torch.float64), tensor([-0.0520], dtype=torch.float64), tensor([0.0276], dtype=torch.float64), tensor([-0.0699], dtype=torch.float64), tensor([0.1175], dtype=torch.float64)]\n",
      "means:  [tensor([0.0431], dtype=torch.float64), tensor([-0.1170], dtype=torch.float64), tensor([-0.0166], dtype=torch.float64), tensor([0.3163], dtype=torch.float64), tensor([0.3602], dtype=torch.float64), tensor([-0.0831], dtype=torch.float64), tensor([0.0140], dtype=torch.float64), tensor([-0.2879], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.2145], dtype=torch.float64), tensor([0.0386], dtype=torch.float64), tensor([0.0833], dtype=torch.float64), tensor([0.4553], dtype=torch.float64), tensor([-0.1556], dtype=torch.float64), tensor([0.0960], dtype=torch.float64), tensor([0.0055], dtype=torch.float64), tensor([0.1462], dtype=torch.float64)]\n",
      "means:  [tensor([0.1098], dtype=torch.float64), tensor([-0.2381], dtype=torch.float64), tensor([-0.0391], dtype=torch.float64), tensor([0.4226], dtype=torch.float64), tensor([0.0188], dtype=torch.float64), tensor([0.0730], dtype=torch.float64), tensor([-0.0927], dtype=torch.float64), tensor([-0.2449], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.2163], dtype=torch.float64), tensor([-0.0817], dtype=torch.float64), tensor([0.0725], dtype=torch.float64), tensor([0.1490], dtype=torch.float64), tensor([-0.0290], dtype=torch.float64), tensor([0.0149], dtype=torch.float64), tensor([-0.0159], dtype=torch.float64), tensor([-0.2935], dtype=torch.float64)]\n",
      "means:  [tensor([0.0514], dtype=torch.float64), tensor([-0.0856], dtype=torch.float64), tensor([-0.0359], dtype=torch.float64), tensor([0.2213], dtype=torch.float64), tensor([0.0791], dtype=torch.float64), tensor([0.0265], dtype=torch.float64), tensor([-0.0078], dtype=torch.float64), tensor([-0.1508], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.0473], dtype=torch.float64), tensor([0.0904], dtype=torch.float64), tensor([0.0182], dtype=torch.float64), tensor([0.2260], dtype=torch.float64), tensor([-0.1503], dtype=torch.float64), tensor([-0.0059], dtype=torch.float64), tensor([-0.0028], dtype=torch.float64), tensor([0.0747], dtype=torch.float64)]\n",
      "means:  [tensor([-0.0629], dtype=torch.float64), tensor([0.0297], dtype=torch.float64), tensor([0.0950], dtype=torch.float64), tensor([0.1668], dtype=torch.float64), tensor([0.2311], dtype=torch.float64), tensor([-0.0199], dtype=torch.float64), tensor([0.0541], dtype=torch.float64), tensor([-0.1571], dtype=torch.float64)]\n",
      "logvar:  [tensor([0.1149], dtype=torch.float64), tensor([-0.0245], dtype=torch.float64), tensor([-0.1048], dtype=torch.float64), tensor([-0.3196], dtype=torch.float64), tensor([-0.2237], dtype=torch.float64), tensor([0.1189], dtype=torch.float64), tensor([-0.0872], dtype=torch.float64), tensor([0.0221], dtype=torch.float64)]\n",
      "means:  [tensor([-0.1654], dtype=torch.float64), tensor([0.0151], dtype=torch.float64), tensor([0.0555], dtype=torch.float64), tensor([0.0179], dtype=torch.float64), tensor([0.0351], dtype=torch.float64), tensor([0.0753], dtype=torch.float64), tensor([-0.0776], dtype=torch.float64), tensor([-0.0882], dtype=torch.float64)]\n",
      "logvar:  [tensor([0.0842], dtype=torch.float64), tensor([-0.1430], dtype=torch.float64), tensor([-0.0566], dtype=torch.float64), tensor([0.0496], dtype=torch.float64), tensor([0.0012], dtype=torch.float64), tensor([0.0963], dtype=torch.float64), tensor([-0.2294], dtype=torch.float64), tensor([-0.1231], dtype=torch.float64)]\n",
      "means:  [tensor([0.1249], dtype=torch.float64), tensor([-0.1292], dtype=torch.float64), tensor([-0.0440], dtype=torch.float64), tensor([0.1998], dtype=torch.float64), tensor([0.0587], dtype=torch.float64), tensor([0.0197], dtype=torch.float64), tensor([-0.0262], dtype=torch.float64), tensor([-0.1064], dtype=torch.float64)]\n",
      "logvar:  [tensor([-0.1422], dtype=torch.float64), tensor([-0.1078], dtype=torch.float64), tensor([0.0986], dtype=torch.float64), tensor([0.0833], dtype=torch.float64), tensor([0.0237], dtype=torch.float64), tensor([-0.0201], dtype=torch.float64), tensor([0.0267], dtype=torch.float64), tensor([0.1995], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "utils.print_user_params(dataloader, print_var = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "path = join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"user_model.h5\")\n",
    "\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data(changes during training)\n",
    "path = join(paths.dat, SETTINGS.rootpaths['models'],\n",
    "                             experiment_name, \"data.h5\")\n",
    "torch.save({\n",
    "    'data': dataloader.dataset.data,\n",
    "}, path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded sim_models\n",
      "total visits for user 6\n",
      "overall_intensity:  tensor([[0.0047]]) \tuser_intensity:  tensor([[0.]]) \tglobal_intensity:  tensor([0.0047]) \t before a recommendation.\n",
      "overall_intensity:  tensor([[0.0047]]) \tuser_intensity:  tensor([[0.]]) \tglobal_intensity:  tensor([0.0047]) \t before a recommendation.\n",
      "overall_intensity:  tensor([[0.0047]]) \tuser_intensity:  tensor([[0.]]) \tglobal_intensity:  tensor([0.0047]) \t before a recommendation.\n",
      "overall_intensity:  tensor([[0.0047]]) \tuser_intensity:  tensor([[0.]]) \tglobal_intensity:  tensor([0.0047]) \t before a recommendation.\n",
      "overall_intensity:  tensor([[0.0047]]) \tuser_intensity:  tensor([[0.]]) \tglobal_intensity:  tensor([0.0047]) \t before a recommendation.\n",
      "overall_intensity:  tensor([[0.0047]]) \tuser_intensity:  tensor([[0.]]) \tglobal_intensity:  tensor([0.0047]) \t before a recommendation.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_models.plot_rnd_user_visits_new(state_size, max_time=max_time, dataset=dataloader.dataset,\n",
    "                    User_model = model, use_true_recommendations =True, num_classes = num_interaction_types,\n",
    "                        teacher_forcing =True, user_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
